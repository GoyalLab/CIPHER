{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858a03cb-e76f-4dcb-8a2d-c955828b1105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIG 2 C\n",
    "import os\n",
    "os.chdir(\"../\")\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from scipy.linalg import eigh\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "# Parameters\n",
    "N = 400           # Number of genes\n",
    "T = 300           # Total time\n",
    "dt = 0.1          # Time step size\n",
    "timesteps = int(T / dt)\n",
    "sigma_K = 1.0     # Std dev of random K entries\n",
    "lambda_base = 1.0 # Self-decay rate\n",
    "D = 0.5           # Noise strength\n",
    "epsilons = np.linspace(0, 0.09, 50)  # Range of coupling strengths\n",
    "\n",
    "# Storage\n",
    "top_eigvals = []\n",
    "pca_variances = []\n",
    "cov_matrices = []\n",
    "\n",
    "# Precompute a single random coupling matrix\n",
    "K = np.random.normal(0, sigma_K , size=(N, N))\n",
    "np.fill_diagonal(K, 0)\n",
    "\n",
    "# Loop over epsilon\n",
    "for epsilon in epsilons:\n",
    "    Lambda = np.diag(np.ones(N) * lambda_base)\n",
    "    A = Lambda + epsilon * K\n",
    "\n",
    "    # Simulate dynamics\n",
    "    x = np.zeros((timesteps, N))\n",
    "    sqrt_2Ddt = np.sqrt(2 * D * dt)\n",
    "    for t in range(1, timesteps):\n",
    "        dx = -A @ x[t - 1] * dt + sqrt_2Ddt * np.random.normal(size=N)\n",
    "        x[t] = x[t - 1] + dx\n",
    "\n",
    "    # Estimate steady-state covariance\n",
    "    steady_state_x = x[int(timesteps / 2):]\n",
    "    cov = np.cov(steady_state_x.T)\n",
    "    cov_matrices.append(cov)\n",
    "\n",
    "    # Compute eigenvalues\n",
    "    eigvals = eigh(cov, eigvals_only=True)[::-1]\n",
    "    top_eigvals.append(eigvals[0])\n",
    "    pca_variances.append(eigvals / np.sum(eigvals))\n",
    "\n",
    "# Convert to arrays\n",
    "top_eigvals = np.array(top_eigvals)\n",
    "pca_variances = np.array(pca_variances)\n",
    "\n",
    "\n",
    "base_dir = \"output\"\n",
    "out_dir = os.path.join(base_dir, \"Fig2\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epsilons, pca_variances[:, 0], label='Top PCA variance')\n",
    "# plt.plot(epsilons, top_eigvals/top_eigvals[-1], label='Top eigenvalue of covariance')\n",
    "plt.xlabel(\"Coupling strength ε\")\n",
    "plt.ylabel(\"Variance explained / Eigenvalue\")\n",
    "plt.title(\"Emergence of Low-Rank Structure\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(out_dir, 'fig_pca_transition.svg'), format='svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2070920-3caf-4853-aa10-2e10c33f5c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIG 2 D\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "# Function to simulate and compute participation ratio over ε for a given N\n",
    "def simulate_participation_vs_epsilon(N, epsilons, T=300, dt=0.1, lambda_base=1.0, D=0.5):\n",
    "    timesteps = int(T / dt)\n",
    "    T_eff = timesteps // 2\n",
    "    np.random.seed(42)\n",
    "    K = np.random.normal(0, 1.0, size=(N, N))\n",
    "    np.fill_diagonal(K, 0)\n",
    "    participation_ratios = []\n",
    "    valid_eps = []\n",
    "\n",
    "    for epsilon in epsilons:\n",
    "        Lambda = np.diag(np.ones(N) * lambda_base)\n",
    "        A = Lambda + epsilon * K\n",
    "        x = np.zeros((timesteps, N))\n",
    "        sqrt_2Ddt = np.sqrt(2 * D * dt)\n",
    "        for t in range(1, timesteps):\n",
    "            dx = -A @ x[t - 1] * dt + sqrt_2Ddt * np.random.normal(size=N)\n",
    "            x[t] = x[t - 1] + dx\n",
    "        steady_state_x = x[int(timesteps / 2):]\n",
    "        cov = np.cov(steady_state_x.T)\n",
    "        if not np.isfinite(cov).all():\n",
    "            continue\n",
    "        eigvals = eigh(cov, eigvals_only=True)[::-1]\n",
    "        total_var = np.sum(eigvals)\n",
    "        total_var_sq = np.sum(eigvals**2)\n",
    "        pr = (total_var**2) / total_var_sq\n",
    "        participation_ratios.append(pr)\n",
    "        valid_eps.append(epsilon)\n",
    "\n",
    "    return np.array(valid_eps), np.array(participation_ratios)\n",
    "\n",
    "# Run for different N\n",
    "Ns = [400, 800, 1200]\n",
    "colors = ['red', 'purple', 'blue']\n",
    "epsilons = np.linspace(0.001, 0.12, 50)\n",
    "\n",
    "# Plot rescaled participation ratio curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for N, color in zip(Ns, colors):\n",
    "    valid_eps, pr = simulate_participation_vs_epsilon(N, epsilons)\n",
    "    eps_scaled = valid_eps * np.sqrt(N)  # rescale ε axis\n",
    "    plt.plot(eps_scaled, pr, label=f\"N = {N}\", color=color)\n",
    "\n",
    "plt.xlabel(r\"Rescaled coupling strength $\\epsilon \\cdot \\sqrt{N}$\")\n",
    "plt.ylabel(\"Participation Ratio\")\n",
    "plt.title(\"Finite-Size Scaling Collapse of Effective Dimensionality\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(out_dir, 'fig_collapse.svg'), format='svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db9d0cb-12a9-4c22-b141-c5c5c51dba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation for FIG 2 E 1 of 3\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import eigh, inv\n",
    "from scipy.linalg import pinv\n",
    "def compute_covariance(X0):\n",
    "    return np.cov(X0, rowvar=False)\n",
    "# Parameters\n",
    "N = 300\n",
    "T = 300\n",
    "dt = 0.05\n",
    "timesteps = int(T / dt)\n",
    "lambda_base = 1.0\n",
    "D = 0.5\n",
    "epsilon = 1/(N)**.5*(1.-.05)  # subcritical but close to transition\n",
    "# epsilon = 1/(N)**.5  # subcritical but close to transition\n",
    "# epsilon = 1/(N)**.5*(1.+.05)  # subcritical but close to transition\n",
    "np.random.seed(42)\n",
    "K = np.random.normal(0, 1.0, size=(N, N))\n",
    "# K = (K + K.T) / 2  # symmetrize\n",
    "np.fill_diagonal(K, 0)\n",
    "A = lambda_base * np.eye(N) + epsilon * K\n",
    "\n",
    "\n",
    "# Compute the smallest real part of the eigenvalues of A\n",
    "eigvals = np.linalg.eigvals(A)\n",
    "lambda_min = np.min(np.real(eigvals))\n",
    "\n",
    "# Estimate relaxation time\n",
    "relax_time = 10 / lambda_min  # heuristic: ~5 relaxation times to reach steady state\n",
    "# T = relax_time\n",
    "# timesteps = int(T/dt)\n",
    "print(f\"Minimum eigenvalue of A (Re part): {lambda_min:.4f}\")\n",
    "print(f\"Recommended minimum simulation time for relaxation: T ≳ {relax_time:.2f}\")\n",
    "\n",
    "\n",
    "# Add step input (constant forcing) to one gene\n",
    "u = np.zeros(N)\n",
    "perturbed_gene = 1\n",
    "u[perturbed_gene] = 1.0\n",
    "\n",
    "from numba import njit\n",
    "\n",
    "from numba import njit\n",
    "import numpy as np\n",
    "\n",
    "# Recompile with nopython=True (enforced by @njit)\n",
    "@njit(nopython=True)\n",
    "def simulate_ou(A, u, with_input, timesteps, N, D, dt):\n",
    "    x = np.zeros((timesteps, N))\n",
    "    sqrt_2Ddt = np.sqrt(2 * D * dt)\n",
    "    zero_vec = np.zeros(N)\n",
    "    force = u if with_input else zero_vec\n",
    "    for t in range(1, timesteps):\n",
    "        noise = np.random.normal(0.0, 1.0, N)\n",
    "        dx = (-A @ x[t - 1] + force) * dt + sqrt_2Ddt * noise\n",
    "        x[t] = x[t - 1] + dx\n",
    "    return x\n",
    "\n",
    "# Test run with current A and u\n",
    "x_perturbed = simulate_ou(A, u, True, timesteps, N, D, dt)\n",
    "x_unperturbed = simulate_ou(A, u, False, timesteps, N, D, dt)\n",
    "\n",
    "\n",
    "\n",
    "# Compute average expression over second half of time series\n",
    "steady_state_x = x_unperturbed[int(timesteps / 2):]\n",
    "Sigma = compute_covariance(steady_state_x)\n",
    "X1 = x_perturbed[timesteps // 2:].mean(axis=0)\n",
    "X0 = x_unperturbed[timesteps // 2:].mean(axis=0)\n",
    "dX = X1 - X0  # observed mean shift due to step input\n",
    "\n",
    "# Compute theoretical prediction using Σ = A⁻¹\n",
    "A_inv = pinv(A)\n",
    "dX_theory = A_inv @ u\n",
    "\n",
    " # Solve for optimal u at gene_index\n",
    "sigma_column = Sigma[:, perturbed_gene]\n",
    "optimal_u = np.dot(sigma_column, dX) / np.dot(sigma_column, sigma_column)\n",
    "# Compute predicted response\n",
    "# dX_theory = optimal_u * sigma_column\n",
    "\n",
    "# Compare results\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(dX, label=\"Simulated dX\", marker='o')\n",
    "plt.plot(dX_theory, label=\"Predicted A⁻¹u\", linestyle='--')\n",
    "plt.xlabel(\"Gene index\")\n",
    "plt.ylabel(\"Mean expression shift\")\n",
    "plt.title(\"Linear Response to Step Input (dX vs A⁻¹u)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Compute R^2 score between simulated and predicted mean shift\n",
    "r2_theory = r2_score(dX, dX_theory)\n",
    "# r2_sigma = r2_score(dX, dX_sigma_simple)\n",
    "\n",
    "print(f\"R² score for A⁻¹ u prediction: {r2_theory:.4f}\")\n",
    "\n",
    "\n",
    "# Run multiple replicates to estimate variance of dX\n",
    "n_repeats = 500\n",
    "dX_all = np.zeros((n_repeats, N))\n",
    "\n",
    "for i in range(n_repeats):\n",
    "    print(i)\n",
    "    x_perturbed = simulate_ou(A, u, True, timesteps, N, D, dt)\n",
    "    x_unperturbed = simulate_ou(A, u, False, timesteps, N, D, dt)\n",
    "    X1 = x_perturbed[timesteps // 2:].mean(axis=0)\n",
    "    X0 = x_unperturbed[timesteps // 2:].mean(axis=0)\n",
    "    dX_all[i] = X1 - X0\n",
    "\n",
    "# Compute mean and standard deviation of dX over replicates\n",
    "dX_mean = dX_all.mean(axis=0)\n",
    "dX_std = dX_all.std(axis=0)\n",
    "\n",
    "# Plot with error bars\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.errorbar(np.arange(N), dX_mean, yerr=dX_std, fmt='o', label=\"Simulated dX ± std\", capsize=2, alpha = .5)\n",
    "plt.plot(dX_theory, label=\"Predicted A⁻¹u\", linestyle='dashdot', color='orange')\n",
    "plt.xlabel(\"Gene index\")\n",
    "plt.ylabel(\"Mean expression shift\")\n",
    "plt.title(\"Linear Response to Step Input with Error Bars\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Compute custom R²-like score accounting for uncertainty from error bars\n",
    "\n",
    "# Define a corrected version of dX where theory is clipped to lie within error bounds\n",
    "dX_lower = dX_mean - dX_std\n",
    "dX_upper = dX_mean + dX_std\n",
    "\n",
    "# Clipping predicted values to fall within the error bars\n",
    "dX_clipped = np.clip(dX_theory, dX_lower, dX_upper)\n",
    "\n",
    "# Compute squared error between clipped prediction and observed mean\n",
    "ss_res = np.sum((dX_mean - dX_clipped) ** 2)\n",
    "\n",
    "# Compute total variance of the observed mean\n",
    "ss_tot = np.sum((dX_mean - np.mean(dX_mean)) ** 2)\n",
    "\n",
    "# Custom R² score with error bar clipping\n",
    "r2_corrected = 1 - ss_res / ss_tot\n",
    "\n",
    "print(f\"R² score accounting for uncertainty bounds: {r2_corrected:.4f}\")\n",
    "\n",
    "\n",
    "linear_data = {\n",
    "    'dX_mean': dX_mean,\n",
    "    'dX_std': dX_std,\n",
    "    'dX_theory': dX_theory,\n",
    "}\n",
    "\n",
    "# # === Optional: save to file ===\n",
    "sub_critical_out = os.path.join(out_dir, \"linear_data_subcritical.pkl\")\n",
    "with open(sub_critical_out, \"wb\") as f:\n",
    "    pickle.dump(linear_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9cfb02-a836-4482-91b8-1cb430e10c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation for FIG 2 E 2 of 3\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import eigh, inv\n",
    "from scipy.linalg import pinv\n",
    "def compute_covariance(X0):\n",
    "    return np.cov(X0, rowvar=False)\n",
    "# Parameters\n",
    "N = 300\n",
    "T = 300\n",
    "dt = 0.05\n",
    "timesteps = int(T / dt)\n",
    "lambda_base = 1.0\n",
    "D = 0.5\n",
    "# epsilon = 1/(N)**.5*(1.-.05)  # subcritical but close to transition\n",
    "epsilon = 1/(N)**.5  # critical \n",
    "# epsilon = 1/(N)**.5*(1.+.05)  # subcritical but close to transition\n",
    "np.random.seed(42)\n",
    "K = np.random.normal(0, 1.0, size=(N, N))\n",
    "# K = (K + K.T) / 2  # symmetrize\n",
    "np.fill_diagonal(K, 0)\n",
    "A = lambda_base * np.eye(N) + epsilon * K\n",
    "\n",
    "\n",
    "# Compute the smallest real part of the eigenvalues of A\n",
    "eigvals = np.linalg.eigvals(A)\n",
    "lambda_min = np.min(np.real(eigvals))\n",
    "\n",
    "# Estimate relaxation time\n",
    "relax_time = 10 / lambda_min  # heuristic: ~5 relaxation times to reach steady state\n",
    "# T = relax_time\n",
    "# timesteps = int(T/dt)\n",
    "print(f\"Minimum eigenvalue of A (Re part): {lambda_min:.4f}\")\n",
    "print(f\"Recommended minimum simulation time for relaxation: T ≳ {relax_time:.2f}\")\n",
    "\n",
    "\n",
    "# Add step input (constant forcing) to one gene\n",
    "u = np.zeros(N)\n",
    "perturbed_gene = 1\n",
    "u[perturbed_gene] = 1.0\n",
    "\n",
    "from numba import njit\n",
    "\n",
    "from numba import njit\n",
    "import numpy as np\n",
    "\n",
    "# Recompile with nopython=True (enforced by @njit)\n",
    "@njit(nopython=True)\n",
    "def simulate_ou(A, u, with_input, timesteps, N, D, dt):\n",
    "    x = np.zeros((timesteps, N))\n",
    "    sqrt_2Ddt = np.sqrt(2 * D * dt)\n",
    "    zero_vec = np.zeros(N)\n",
    "    force = u if with_input else zero_vec\n",
    "    for t in range(1, timesteps):\n",
    "        noise = np.random.normal(0.0, 1.0, N)\n",
    "        dx = (-A @ x[t - 1] + force) * dt + sqrt_2Ddt * noise\n",
    "        x[t] = x[t - 1] + dx\n",
    "    return x\n",
    "\n",
    "# Test run with current A and u\n",
    "x_perturbed = simulate_ou(A, u, True, timesteps, N, D, dt)\n",
    "x_unperturbed = simulate_ou(A, u, False, timesteps, N, D, dt)\n",
    "\n",
    "\n",
    "\n",
    "# Compute average expression over second half of time series\n",
    "steady_state_x = x_unperturbed[int(timesteps / 2):]\n",
    "Sigma = compute_covariance(steady_state_x)\n",
    "X1 = x_perturbed[timesteps // 2:].mean(axis=0)\n",
    "X0 = x_unperturbed[timesteps // 2:].mean(axis=0)\n",
    "dX = X1 - X0  # observed mean shift due to step input\n",
    "\n",
    "# Compute theoretical prediction using Σ = A⁻¹\n",
    "A_inv = pinv(A)\n",
    "dX_theory = A_inv @ u\n",
    "\n",
    " # Solve for optimal u at gene_index\n",
    "sigma_column = Sigma[:, perturbed_gene]\n",
    "optimal_u = np.dot(sigma_column, dX) / np.dot(sigma_column, sigma_column)\n",
    "# Compute predicted response\n",
    "# dX_theory = optimal_u * sigma_column\n",
    "\n",
    "# Compare results\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(dX, label=\"Simulated dX\", marker='o')\n",
    "plt.plot(dX_theory, label=\"Predicted A⁻¹u\", linestyle='--')\n",
    "plt.xlabel(\"Gene index\")\n",
    "plt.ylabel(\"Mean expression shift\")\n",
    "plt.title(\"Linear Response to Step Input (dX vs A⁻¹u)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Compute R^2 score between simulated and predicted mean shift\n",
    "r2_theory = r2_score(dX, dX_theory)\n",
    "# r2_sigma = r2_score(dX, dX_sigma_simple)\n",
    "\n",
    "print(f\"R² score for A⁻¹ u prediction: {r2_theory:.4f}\")\n",
    "\n",
    "\n",
    "# Run multiple replicates to estimate variance of dX\n",
    "n_repeats = 500\n",
    "dX_all = np.zeros((n_repeats, N))\n",
    "\n",
    "for i in range(n_repeats):\n",
    "    print(i)\n",
    "    x_perturbed = simulate_ou(A, u, True, timesteps, N, D, dt)\n",
    "    x_unperturbed = simulate_ou(A, u, False, timesteps, N, D, dt)\n",
    "    X1 = x_perturbed[timesteps // 2:].mean(axis=0)\n",
    "    X0 = x_unperturbed[timesteps // 2:].mean(axis=0)\n",
    "    dX_all[i] = X1 - X0\n",
    "\n",
    "# Compute mean and standard deviation of dX over replicates\n",
    "dX_mean = dX_all.mean(axis=0)\n",
    "dX_std = dX_all.std(axis=0)\n",
    "\n",
    "# Plot with error bars\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.errorbar(np.arange(N), dX_mean, yerr=dX_std, fmt='o', label=\"Simulated dX ± std\", capsize=2, alpha = .5)\n",
    "plt.plot(dX_theory, label=\"Predicted A⁻¹u\", linestyle='dashdot', color='orange')\n",
    "plt.xlabel(\"Gene index\")\n",
    "plt.ylabel(\"Mean expression shift\")\n",
    "plt.title(\"Linear Response to Step Input with Error Bars\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Compute custom R²-like score accounting for uncertainty from error bars\n",
    "\n",
    "# Define a corrected version of dX where theory is clipped to lie within error bounds\n",
    "dX_lower = dX_mean - dX_std\n",
    "dX_upper = dX_mean + dX_std\n",
    "\n",
    "# Clipping predicted values to fall within the error bars\n",
    "dX_clipped = np.clip(dX_theory, dX_lower, dX_upper)\n",
    "\n",
    "# Compute squared error between clipped prediction and observed mean\n",
    "ss_res = np.sum((dX_mean - dX_clipped) ** 2)\n",
    "\n",
    "# Compute total variance of the observed mean\n",
    "ss_tot = np.sum((dX_mean - np.mean(dX_mean)) ** 2)\n",
    "\n",
    "# Custom R² score with error bar clipping\n",
    "r2_corrected = 1 - ss_res / ss_tot\n",
    "\n",
    "print(f\"R² score accounting for uncertainty bounds: {r2_corrected:.4f}\")\n",
    "\n",
    "\n",
    "linear_data = {\n",
    "    'dX_mean': dX_mean,\n",
    "    'dX_std': dX_std,\n",
    "    'dX_theory': dX_theory,\n",
    "}\n",
    "\n",
    "# # === Optional: save to file ===\n",
    "crit_out = os.path.join(out_dir, \"linear_data_critical.pkl\")\n",
    "with open(crit_out, \"wb\") as f:\n",
    "    pickle.dump(linear_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc2598e-0fa0-45a6-ad91-a2ec95b43b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation for FIG 2 E 3 of 3\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import eigh, inv\n",
    "from scipy.linalg import pinv\n",
    "def compute_covariance(X0):\n",
    "    return np.cov(X0, rowvar=False)\n",
    "# Parameters\n",
    "N = 300\n",
    "T = 300\n",
    "dt = 0.05\n",
    "timesteps = int(T / dt)\n",
    "lambda_base = 1.0\n",
    "D = 0.5\n",
    "# epsilon = 1/(N)**.5*(1.-.05)  # subcritical but close to transition\n",
    "# epsilon = 1/(N)**.5  # subcritical but close to transition\n",
    "epsilon = 1/(N)**.5*(1.+.05)  # subcritical but close to transition\n",
    "np.random.seed(42)\n",
    "K = np.random.normal(0, 1.0, size=(N, N))\n",
    "# K = (K + K.T) / 2  # symmetrize\n",
    "np.fill_diagonal(K, 0)\n",
    "A = lambda_base * np.eye(N) + epsilon * K\n",
    "\n",
    "\n",
    "# Compute the smallest real part of the eigenvalues of A\n",
    "eigvals = np.linalg.eigvals(A)\n",
    "lambda_min = np.min(np.real(eigvals))\n",
    "\n",
    "# Estimate relaxation time\n",
    "relax_time = 10 / lambda_min  # heuristic: ~5 relaxation times to reach steady state\n",
    "# T = relax_time\n",
    "# timesteps = int(T/dt)\n",
    "print(f\"Minimum eigenvalue of A (Re part): {lambda_min:.4f}\")\n",
    "print(f\"Recommended minimum simulation time for relaxation: T ≳ {relax_time:.2f}\")\n",
    "\n",
    "\n",
    "# Add step input (constant forcing) to one gene\n",
    "u = np.zeros(N)\n",
    "perturbed_gene = 1\n",
    "u[perturbed_gene] = 1.0\n",
    "\n",
    "from numba import njit\n",
    "\n",
    "from numba import njit\n",
    "import numpy as np\n",
    "\n",
    "# Recompile with nopython=True (enforced by @njit)\n",
    "@njit(nopython=True)\n",
    "def simulate_ou(A, u, with_input, timesteps, N, D, dt):\n",
    "    x = np.zeros((timesteps, N))\n",
    "    sqrt_2Ddt = np.sqrt(2 * D * dt)\n",
    "    zero_vec = np.zeros(N)\n",
    "    force = u if with_input else zero_vec\n",
    "    for t in range(1, timesteps):\n",
    "        noise = np.random.normal(0.0, 1.0, N)\n",
    "        dx = (-A @ x[t - 1] + force) * dt + sqrt_2Ddt * noise\n",
    "        x[t] = x[t - 1] + dx\n",
    "    return x\n",
    "\n",
    "# Test run with current A and u\n",
    "x_perturbed = simulate_ou(A, u, True, timesteps, N, D, dt)\n",
    "x_unperturbed = simulate_ou(A, u, False, timesteps, N, D, dt)\n",
    "\n",
    "\n",
    "\n",
    "# Compute average expression over second half of time series\n",
    "steady_state_x = x_unperturbed[int(timesteps / 2):]\n",
    "Sigma = compute_covariance(steady_state_x)\n",
    "X1 = x_perturbed[timesteps // 2:].mean(axis=0)\n",
    "X0 = x_unperturbed[timesteps // 2:].mean(axis=0)\n",
    "dX = X1 - X0  # observed mean shift due to step input\n",
    "\n",
    "# Compute theoretical prediction using Σ = A⁻¹\n",
    "A_inv = pinv(A)\n",
    "dX_theory = A_inv @ u\n",
    "\n",
    " # Solve for optimal u at gene_index\n",
    "sigma_column = Sigma[:, perturbed_gene]\n",
    "optimal_u = np.dot(sigma_column, dX) / np.dot(sigma_column, sigma_column)\n",
    "# Compute predicted response\n",
    "# dX_theory = optimal_u * sigma_column\n",
    "\n",
    "# Compare results\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(dX, label=\"Simulated dX\", marker='o')\n",
    "plt.plot(dX_theory, label=\"Predicted A⁻¹u\", linestyle='--')\n",
    "plt.xlabel(\"Gene index\")\n",
    "plt.ylabel(\"Mean expression shift\")\n",
    "plt.title(\"Linear Response to Step Input (dX vs A⁻¹u)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Compute R^2 score between simulated and predicted mean shift\n",
    "r2_theory = r2_score(dX, dX_theory)\n",
    "# r2_sigma = r2_score(dX, dX_sigma_simple)\n",
    "\n",
    "print(f\"R² score for A⁻¹ u prediction: {r2_theory:.4f}\")\n",
    "\n",
    "\n",
    "# Run multiple replicates to estimate variance of dX\n",
    "n_repeats = 500\n",
    "dX_all = np.zeros((n_repeats, N))\n",
    "\n",
    "for i in range(n_repeats):\n",
    "    print(i)\n",
    "    x_perturbed = simulate_ou(A, u, True, timesteps, N, D, dt)\n",
    "    x_unperturbed = simulate_ou(A, u, False, timesteps, N, D, dt)\n",
    "    X1 = x_perturbed[timesteps // 2:].mean(axis=0)\n",
    "    X0 = x_unperturbed[timesteps // 2:].mean(axis=0)\n",
    "    dX_all[i] = X1 - X0\n",
    "\n",
    "# Compute mean and standard deviation of dX over replicates\n",
    "dX_mean = dX_all.mean(axis=0)\n",
    "dX_std = dX_all.std(axis=0)\n",
    "\n",
    "# Plot with error bars\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.errorbar(np.arange(N), dX_mean, yerr=dX_std, fmt='o', label=\"Simulated dX ± std\", capsize=2, alpha = .5)\n",
    "plt.plot(dX_theory, label=\"Predicted A⁻¹u\", linestyle='dashdot', color='orange')\n",
    "plt.xlabel(\"Gene index\")\n",
    "plt.ylabel(\"Mean expression shift\")\n",
    "plt.title(\"Linear Response to Step Input with Error Bars\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Compute custom R²-like score accounting for uncertainty from error bars\n",
    "\n",
    "# Define a corrected version of dX where theory is clipped to lie within error bounds\n",
    "dX_lower = dX_mean - dX_std\n",
    "dX_upper = dX_mean + dX_std\n",
    "\n",
    "# Clipping predicted values to fall within the error bars\n",
    "dX_clipped = np.clip(dX_theory, dX_lower, dX_upper)\n",
    "\n",
    "# Compute squared error between clipped prediction and observed mean\n",
    "ss_res = np.sum((dX_mean - dX_clipped) ** 2)\n",
    "\n",
    "# Compute total variance of the observed mean\n",
    "ss_tot = np.sum((dX_mean - np.mean(dX_mean)) ** 2)\n",
    "\n",
    "# Custom R² score with error bar clipping\n",
    "r2_corrected = 1 - ss_res / ss_tot\n",
    "\n",
    "print(f\"R² score accounting for uncertainty bounds: {r2_corrected:.4f}\")\n",
    "\n",
    "\n",
    "linear_data = {\n",
    "    'dX_mean': dX_mean,\n",
    "    'dX_std': dX_std,\n",
    "    'dX_theory': dX_theory,\n",
    "}\n",
    "\n",
    "# # === Optional: save to file ===\n",
    "supercrit_out = os.path.join(out_dir, \"linear_data_supercritical.pkl\")\n",
    "with open(supercrit_out, \"wb\") as f:\n",
    "    pickle.dump(linear_data, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac880c55-9e66-4938-833f-c2daa7264187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f890fa-cd36-4105-8c80-f5dd2a967d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIG 2 E\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# === File names and labels ===\n",
    "file_labels = [\n",
    "    (sub_critical_out, \"Subcritical\"),\n",
    "    (crit_out, \"Critical\"),\n",
    "    (supercrit_out, \"Supercritical\"),\n",
    "]\n",
    "\n",
    "# === Store results ===\n",
    "rel_errors = []\n",
    "rel_errors_std = []\n",
    "labels = []\n",
    "\n",
    "# === Process each dataset ===\n",
    "for filename, label in file_labels:\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    dX_mean = data[\"dX_mean\"]\n",
    "    dX_std = data[\"dX_std\"]\n",
    "    dX_theory = data[\"dX_theory\"]\n",
    "\n",
    "    # Compute relative error\n",
    "    numerator = np.linalg.norm(dX_theory - dX_mean)\n",
    "    denominator = np.linalg.norm(dX_theory)\n",
    "    rel_error = numerator / denominator\n",
    "\n",
    "    # Error propagation: std of ||dX_theory - dX_mean||\n",
    "    propagated_std = np.sqrt(np.sum(dX_std ** 2))\n",
    "    rel_error_std = propagated_std / denominator\n",
    "\n",
    "    # Store results\n",
    "    rel_errors.append(rel_error)\n",
    "    rel_errors_std.append(rel_error_std)\n",
    "    labels.append(label)\n",
    "\n",
    "# === Plot ===\n",
    "plt.figure(figsize=(6, 4))\n",
    "x = np.arange(len(labels))\n",
    "plt.errorbar(x, rel_errors, yerr=rel_errors_std, fmt='o', capsize=5, color='black')\n",
    "plt.xticks(x, labels)\n",
    "plt.ylabel(\"Relative Linear Response Error\\n$\\\\|dX_\\\\mathrm{theory} - dX_\\\\mathrm{mean}\\\\| \\\\, / \\\\, \\\\|dX_\\\\mathrm{theory}\\\\|$\")\n",
    "plt.title(\"Relative Error Across Regimes\")\n",
    "plt.tight_layout()\n",
    "plt.yscale('log')\n",
    "plt_out = os.path.join(out_dir, \"relative_error_linear_response_across_regimes.svg\")\n",
    "plt.savefig(plt_out, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "\n",
    "# === Load and build error vectors ===\n",
    "error_dict = {}\n",
    "for filename, label in file_labels:\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    dX_mean   = data[\"dX_mean\"]\n",
    "    dX_std    = data[\"dX_std\"]    # not needed for the test itself\n",
    "    dX_theory = data[\"dX_theory\"]\n",
    "\n",
    "    # elementwise relative error: |theory - mean| / |theory|\n",
    "    # add a tiny eps to denominator to avoid div-by-zero\n",
    "    eps = 1e-10\n",
    "    err_vec = np.abs(dX_theory - dX_mean) / (np.abs(dX_theory) + eps)\n",
    "    error_dict[label] = err_vec\n",
    "\n",
    "# === One-sided Wilcoxon tests ===\n",
    "sub = error_dict[\"Subcritical\"]\n",
    "crit = error_dict[\"Critical\"]\n",
    "sup = error_dict[\"Supercritical\"]\n",
    "\n",
    "print(\"Wilcoxon signed-rank tests (one-sided):\\n\")\n",
    "\n",
    "# Test Subcritical < Critical\n",
    "stat_sc, p_sc = wilcoxon(sub, crit, alternative=\"less\")\n",
    "print(f\"Subcritical < Critical: stat = {stat_sc:.4f}, p = {p_sc:.4g}\")\n",
    "\n",
    "# Test Critical < Supercritical\n",
    "stat_cs, p_cs = wilcoxon(crit, sup, alternative=\"less\")\n",
    "print(f\"Critical   < Supercritical: stat = {stat_cs:.4f}, p = {p_cs:.4g}\")\n",
    "\n",
    "# (Optional) Test Subcritical < Supercritical\n",
    "stat_ss, p_ss = wilcoxon(sub, sup, alternative=\"less\")\n",
    "print(f\"Subcritical < Supercritical: stat = {stat_ss:.4f}, p = {p_ss:.4g}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5416aca7-2edd-4606-9ade-eb344f469500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91a3ff4-788d-4d51-8d39-2d43ba3f96ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f3a4a-84a7-40cd-9ecf-35b338444e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIG 2 H\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import inv\n",
    "\n",
    "# --------------------------\n",
    "# Parameters\n",
    "# --------------------------\n",
    "N = 10           # Number of genes\n",
    "K = 10.0         # Hill coefficient\n",
    "gamma = 1.0      # Decay rate\n",
    "G_mean = 1.0\n",
    "G_std = 0.1\n",
    "x_init = np.ones(N) * K\n",
    "magnitudes = np.logspace(-2, 2, 60)\n",
    "hill_exponents = [0.,1.0, 2.0, 4.0, 6.0, 8.]\n",
    "hill_error_curves = {}\n",
    "\n",
    "# --------------------------\n",
    "# Core Functions\n",
    "# --------------------------\n",
    "def H(x, n):\n",
    "    return x**n / (K**n + x**n)\n",
    "\n",
    "def dH(x, n):\n",
    "    return (n * K**n * x**(n - 1)) / (K**n + x**n)**2\n",
    "\n",
    "def f(x):\n",
    "    return gamma * x\n",
    "\n",
    "def find_steady_state(G, n, x_init, tol=1e-14, max_iter=2000):\n",
    "    x = x_init.copy()\n",
    "    for _ in range(max_iter):\n",
    "        dx = -f(x) + G @ H(x, n)\n",
    "        if np.linalg.norm(dx) < tol:\n",
    "            break\n",
    "        x += 0.01 * dx\n",
    "    return x\n",
    "\n",
    "def simulate_perturbed_steady_state(G, n, x_init, u, tol=1e-14, max_iter=2000):\n",
    "    x = x_init.copy()\n",
    "    for _ in range(max_iter):\n",
    "        dx = -f(x) + G @ H(x, n) + u\n",
    "        if np.linalg.norm(dx) < tol:\n",
    "            break\n",
    "        x += 0.01 * dx\n",
    "    return x\n",
    "\n",
    "# --------------------------\n",
    "# Hill Exponent Sweep\n",
    "# --------------------------\n",
    "for n_val in hill_exponents:\n",
    "    G = np.abs(np.random.normal(loc=G_mean, scale=G_std, size=(N, N)))\n",
    "    x0 = find_steady_state(G, n_val, x_init)\n",
    "    H_prime_diag = np.diag(dH(x0, n_val))\n",
    "    D = np.eye(N) * gamma\n",
    "    J = -D + G @ H_prime_diag\n",
    "\n",
    "    errors = []\n",
    "    for mag in magnitudes:\n",
    "        u = np.zeros(N)\n",
    "        u[1] = mag\n",
    "        # u[3] = mag\n",
    "        delta_x_lin = -inv(J) @ u\n",
    "        x_pert = simulate_perturbed_steady_state(G, n_val, x_init, u)\n",
    "        delta_x_emp = x_pert - x0\n",
    "        error = np.linalg.norm(delta_x_emp - delta_x_lin) / np.linalg.norm(delta_x_emp)\n",
    "        errors.append(error)\n",
    "\n",
    "    hill_error_curves[f\"n = {n_val}\"] = errors\n",
    "\n",
    "# --------------------------\n",
    "# Plotting\n",
    "# --------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "for label, errors in hill_error_curves.items():\n",
    "    plt.plot(magnitudes, errors, marker='o', label=label)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Perturbation magnitude', fontsize=20)\n",
    "plt.ylabel('Relative error of linear response', fontsize=20)\n",
    "# plt.title('Effect of Hill exponent on linear response breakdown', fontsize=20)\n",
    "plt.legend(fontsize=14)\n",
    "# plt.grid(True)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt_out = os.path.join(out_dir, 'hill_net_n.svg')\n",
    "plt.savefig(plt_out, format='svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2232ef6f-6fb5-455f-a5a2-7c816622ec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIG S1 A\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import inv\n",
    "\n",
    "# --------------------------\n",
    "# Parameters\n",
    "# --------------------------\n",
    "N = 10           # Number of genes\n",
    "K = 10.0         # Hill parameter\n",
    "gamma = 1.0      # Decay rate\n",
    "G_mean = 1.0\n",
    "G_std = 0.1\n",
    "x_init = np.ones(N) * K\n",
    "magnitudes = np.logspace(-2, 2, 60)  # Per-gene perturbation magnitudes\n",
    "hill_exponents = [0., 1.0, 2.0, 4.0]\n",
    "max_k = 5                            # Max number of perturbed genes\n",
    "n_trials = 20                        # Number of trials per setting\n",
    "\n",
    "# --------------------------\n",
    "# Core Functions\n",
    "# --------------------------\n",
    "def H(x, n):\n",
    "    return x**n / (K**n + x**n)\n",
    "\n",
    "def dH(x, n):\n",
    "    return (n * K**n * x**(n - 1)) / (K**n + x**n)**2\n",
    "\n",
    "def f(x):\n",
    "    return gamma * x\n",
    "\n",
    "def find_steady_state(G, n, x_init, tol=1e-12, max_iter=2000):\n",
    "    x = x_init.copy()\n",
    "    for _ in range(max_iter):\n",
    "        dx = -f(x) + G @ H(x, n)\n",
    "        if np.linalg.norm(dx) < tol:\n",
    "            break\n",
    "        x += 0.01 * dx\n",
    "    return x\n",
    "\n",
    "def simulate_perturbed_steady_state(G, n, x_init, u, tol=1e-12, max_iter=2000):\n",
    "    x = x_init.copy()\n",
    "    for _ in range(max_iter):\n",
    "        dx = -f(x) + G @ H(x, n) + u\n",
    "        if np.linalg.norm(dx) < tol:\n",
    "            break\n",
    "        x += 0.01 * dx\n",
    "    return x\n",
    "\n",
    "def generate_equal_magnitude_u(N, k, mag):\n",
    "    \"\"\"Return a vector u with exactly k entries equal to +mag, others zero.\"\"\"\n",
    "    u = np.zeros(N)\n",
    "    indices = np.random.choice(N, k, replace=False)\n",
    "    u[indices] = mag\n",
    "    return u\n",
    "\n",
    "# --------------------------\n",
    "# Main Loop: Hill × k × magnitude\n",
    "# --------------------------\n",
    "all_errors = {}  # {(n_val, k): [list of errors vs mag]}\n",
    "\n",
    "for n_val in hill_exponents:\n",
    "    G = np.abs(np.random.normal(loc=G_mean, scale=G_std, size=(N, N)))\n",
    "    x0 = find_steady_state(G, n_val, x_init)\n",
    "    H_prime_diag = np.diag(dH(x0, n_val))\n",
    "    D = np.eye(N) * gamma\n",
    "    J = -D + G @ H_prime_diag\n",
    "    J_inv = inv(J)\n",
    "\n",
    "    for k in range(1, max_k + 1):\n",
    "        curve = []\n",
    "        for mag in magnitudes:\n",
    "            rel_errors = []\n",
    "            for _ in range(n_trials):\n",
    "                u = generate_equal_magnitude_u(N, k, mag)\n",
    "                dx_lin = -J_inv @ u\n",
    "                x_pert = simulate_perturbed_steady_state(G, n_val, x0, u)\n",
    "                dx_true = x_pert - x0\n",
    "                err = np.linalg.norm(dx_true - dx_lin) / np.linalg.norm(dx_true)\n",
    "                rel_errors.append(err)\n",
    "            curve.append(np.mean(rel_errors))\n",
    "        all_errors[(n_val, k)] = curve\n",
    "\n",
    "# --------------------------\n",
    "# Plotting\n",
    "# --------------------------\n",
    "for n_val in hill_exponents:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for k in range(1, max_k + 1):\n",
    "        label = f\"{k} perturbed genes\"\n",
    "        plt.plot(magnitudes, all_errors[(n_val, k)], label=label, marker='o')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Per-gene perturbation magnitude', fontsize=16)\n",
    "    plt.ylabel('Relative linear response error', fontsize=16)\n",
    "    plt.title(f\"Hill exponent n = {n_val}\", fontsize=16)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt_out = os.path.join(out_dir, f\"hill_n_{n_val}_equal_mag_per_gene.svg\")\n",
    "    plt.savefig(plt_out, format='svg')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454741e4-5f80-4ee2-88df-0c18b51dcdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIG 2 G\n",
    "\n",
    "# We'll fix several perturbation magnitudes and compute error as a function of G\n",
    "n = 4.0\n",
    "\n",
    "def find_steady_state(G, n, x_init, tol=1e-14, max_iter=2000):\n",
    "    x = x_init.copy()\n",
    "    for _ in range(max_iter):\n",
    "        dx = -f(x) + G @ H(x, n)\n",
    "        if np.linalg.norm(dx) < tol:\n",
    "            break\n",
    "        x += 0.01 * dx\n",
    "    return x\n",
    "\n",
    "def simulate_perturbed_steady_state(G, n, x_init, u, tol=1e-14, max_iter=2000):\n",
    "    x = x_init.copy()\n",
    "    for _ in range(max_iter):\n",
    "        dx = -f(x) + G @ H(x, n) + u\n",
    "        if np.linalg.norm(dx) < tol:\n",
    "            break\n",
    "        x += 0.01 * dx\n",
    "    return x\n",
    "\n",
    "\n",
    "    \n",
    "selected_mags = [0.1, 0.3, 1.0]\n",
    "G_vals = np.linspace(0.5, 3.5, 300)\n",
    "error_vs_G = {mag: [] for mag in selected_mags}\n",
    "def f(x):\n",
    "    return gamma * x\n",
    "for G_val in G_vals:\n",
    "    G = np.abs(np.random.normal(loc=G_val, scale=G_std, size=(N, N)))\n",
    "    x0 = find_steady_state(G, n, x_init)\n",
    "    H_prime_diag = np.diag(dH(x0, n))\n",
    "    D = np.eye(N) * gamma\n",
    "    J = -D + G @ H_prime_diag\n",
    "\n",
    "    for mag in selected_mags:\n",
    "        u = np.zeros(N)\n",
    "        u[1] = mag\n",
    "        # u[3] = mag\n",
    "        delta_x_lin = -inv(J) @ u\n",
    "        x_pert = simulate_perturbed_steady_state(G, n, x_init, u)\n",
    "        delta_x_emp = x_pert - x0\n",
    "        error = np.linalg.norm(delta_x_emp - delta_x_lin) / np.linalg.norm(delta_x_emp)\n",
    "        error_vs_G[mag].append(error)\n",
    "\n",
    "# --------------------------\n",
    "# Plotting\n",
    "# --------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "for mag in selected_mags:\n",
    "    plt.plot(G_vals/2., error_vs_G[mag], marker='o', label=f\"|u| = {mag}\")\n",
    "\n",
    "plt.xlabel('Interaction strength G_eff', fontsize=20)\n",
    "plt.ylabel('Relative error of linear response', fontsize=20)\n",
    "# plt.title('Error vs G at fixed perturbation magnitudes', fontsize=20)\n",
    "plt.legend(fontsize=14)\n",
    "plt.yscale('log')\n",
    "# plt.grid(True)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt_out = os.path.join(out_dir, 'Fig2G.svg')\n",
    "plt.savefig(plt_out, format='svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66d9b49-8781-4939-9663-f4ca50e81ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    " # FIG S1 B\n",
    "\n",
    "# Redefine everything cleanly with K as an argument for modularity\n",
    "# Sweep over K values for fixed G, n, and gamma\n",
    "K_vals = np.linspace(.1, 25.0, 300)\n",
    "selected_mags = [0.1, 0.3, 1.0]\n",
    "error_vs_K = {mag: [] for mag in selected_mags}\n",
    "\n",
    "# Fixed system parameters\n",
    "G_val = 1.\n",
    "n = 4.0\n",
    "gamma = 1.0\n",
    "def f(x):\n",
    "    return gamma * x\n",
    "def H(x, K_val):\n",
    "    return x**n / (K_val**n + x**n)\n",
    "\n",
    "def dH(x, K_val):\n",
    "    return (n * K_val**n * x**(n - 1)) / (K_val**n + x**n)**2\n",
    "\n",
    "def find_steady_state(G, K_val, x_init, tol=1e-12, max_iter=2000):\n",
    "    x = x_init.copy()\n",
    "    for _ in range(max_iter):\n",
    "        dx = -f(x) + G @ H(x, K_val)\n",
    "        if np.linalg.norm(dx) < tol:\n",
    "            break\n",
    "        x += 0.1 * dx\n",
    "    return x\n",
    "\n",
    "def simulate_perturbed_steady_state(G, K_val, x_init, u, tol=1e-12, max_iter=2000):\n",
    "    x = x_init.copy()\n",
    "    for _ in range(max_iter):\n",
    "        dx = -f(x) + G @ H(x, K_val) + u\n",
    "        if np.linalg.norm(dx) < tol:\n",
    "            break\n",
    "        x += 0.1 * dx\n",
    "    return x\n",
    "\n",
    "# Now rerun the K sweep\n",
    "error_vs_K = {mag: [] for mag in selected_mags}\n",
    "\n",
    "for K_test in K_vals:\n",
    "    G = np.abs(np.random.normal(loc=G_val, scale=G_std, size=(N, N)))\n",
    "    x0 = find_steady_state(G, K_test, x_init)\n",
    "    H_prime_diag = np.diag(dH(x0, K_test))\n",
    "    D = np.eye(N) * gamma\n",
    "    J = -D + G @ H_prime_diag\n",
    "\n",
    "    for mag in selected_mags:\n",
    "        u = np.zeros(N)\n",
    "        u[1] = mag\n",
    "        # u[3] = mag\n",
    "        delta_x_lin = -inv(J) @ u\n",
    "        x_pert = simulate_perturbed_steady_state(G, K_test, x_init, u)\n",
    "        delta_x_emp = x_pert - x0\n",
    "        error = np.linalg.norm(delta_x_emp - delta_x_lin) / np.linalg.norm(delta_x_emp)\n",
    "        error_vs_K[mag].append(error)\n",
    "\n",
    "# --------------------------\n",
    "# Plotting\n",
    "# --------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "for mag in selected_mags:\n",
    "    plt.plot(K_vals, error_vs_K[mag], marker='o', label=f\"|u| = {mag}\")\n",
    "\n",
    "plt.xlabel('K (Hill saturation parameter)', fontsize=20)\n",
    "plt.ylabel('Relative error of linear response', fontsize=20)\n",
    "# plt.title('Effect of K on linear response accuracy (fixed G, n)', fontsize=20)\n",
    "plt.legend(fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.yscale('log')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt_out = os.path.join(out_dir, 'FigS1B.svg')\n",
    "plt.savefig(plt_out, format='svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcdd4e4-ef8c-41ee-8ea8-a8446e63fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    " # FIG S1 C\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import inv\n",
    "\n",
    "# Parameters\n",
    "N = 10\n",
    "K = 10.0\n",
    "n = 4.0\n",
    "G_mean = 1.0\n",
    "G_std = 0.1\n",
    "x_init = np.ones(N) * K\n",
    "magnitudes = [0.1, 0.3, 1.0]\n",
    "gamma_vals = np.linspace(0.01, 3.0, 300)\n",
    "error_vs_gamma = {mag: [] for mag in magnitudes}\n",
    "\n",
    "# Core functions with fixed n and K\n",
    "def H(x):\n",
    "    return x**n / (K**n + x**n)\n",
    "\n",
    "def dH(x):\n",
    "    return (n * K**n * x**(n - 1)) / (K**n + x**n)**2\n",
    "\n",
    "def f(x, gamma):\n",
    "    return gamma * x\n",
    "\n",
    "def find_steady_state(G, gamma, x_init, tol=1e-12, max_iter=2000):\n",
    "    x = x_init.copy()\n",
    "    for _ in range(max_iter):\n",
    "        dx = -f(x, gamma) + G @ H(x)\n",
    "        if np.linalg.norm(dx) < tol:\n",
    "            break\n",
    "        x += 0.1 * dx\n",
    "    return x\n",
    "\n",
    "def simulate_perturbed_steady_state(G, gamma, x_init, u, tol=1e-12, max_iter=2000):\n",
    "    x = x_init.copy()\n",
    "    for _ in range(max_iter):\n",
    "        dx = -f(x, gamma) + G @ H(x) + u\n",
    "        if np.linalg.norm(dx) < tol:\n",
    "            break\n",
    "        x += 0.1 * dx\n",
    "    return x\n",
    "\n",
    "# Run the sweep\n",
    "for gamma in gamma_vals:\n",
    "    G = np.abs(np.random.normal(loc=G_mean, scale=G_std, size=(N, N)))\n",
    "    x0 = find_steady_state(G, gamma, x_init)\n",
    "    H_prime_diag = np.diag(dH(x0))\n",
    "    D = np.eye(N) * gamma\n",
    "    J = -D + G @ H_prime_diag\n",
    "\n",
    "    for mag in magnitudes:\n",
    "        u = np.zeros(N)\n",
    "        u[1] = mag\n",
    "        u[3] = mag\n",
    "        delta_x_lin = -inv(J) @ u\n",
    "        x_pert = simulate_perturbed_steady_state(G, gamma, x_init, u)\n",
    "        delta_x_emp = x_pert - x0\n",
    "        error = np.linalg.norm(delta_x_emp - delta_x_lin) / np.linalg.norm(delta_x_emp)\n",
    "        error_vs_gamma[mag].append(error)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "for mag in magnitudes:\n",
    "    plt.plot(gamma_vals, error_vs_gamma[mag], marker='o', label=f\"mag = {mag}\")\n",
    "\n",
    "plt.xlabel('Decay rate γ', fontsize=20)\n",
    "plt.ylabel('Relative error of linear response', fontsize=20)\n",
    "plt.title('Effect of decay rate on linear response accuracy', fontsize=20)\n",
    "plt.legend(fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.yscale('log')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt_out = os.path.join(out_dir, 'FigS1C.svg')\n",
    "plt.savefig(plt_out, format='svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa57251-87cd-4fb1-b6d5-f4d670337fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c9a150-be92-42e1-9b3a-c9065e2e16e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48122157-4d89-492c-9555-a65ae4c2d1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35b4539-350a-4b6c-a5ac-05370eca692d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bb38b1-1f7b-402a-8ed9-01eb20aa42fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de00272-b2dc-4a92-be16-5627c8a3b030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eec8c3-25cf-46f3-98b6-e3b2b949dead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d0dd19-fd38-4043-8d15-c78481c63612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae407f5a-86e4-471d-b2a1-5f7def6d9586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIG 2 J, K, L\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import njit\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# ---------------------------\n",
    "# Parameters\n",
    "# ---------------------------\n",
    "N_genes = 20\n",
    "T = 2*10**6\n",
    "dt = 0.1\n",
    "time = np.arange(T) * dt\n",
    "\n",
    "beta = np.ones(N_genes) * 50.0\n",
    "gamma = np.ones(N_genes) * 4.0\n",
    "K = 25.0\n",
    "n = 2.0\n",
    "noise_strength = .5\n",
    "\n",
    "# ---------------------------\n",
    "# Team structure: A vs B\n",
    "# ---------------------------\n",
    "group_A = np.arange(0, N_genes // 2)\n",
    "group_B = np.arange(N_genes // 2, N_genes)\n",
    "\n",
    "B_on = np.zeros((N_genes, N_genes))\n",
    "B_off = np.zeros((N_genes, N_genes))\n",
    "randscale = .45\n",
    "# Within-team activation\n",
    "for i in group_A:\n",
    "    for j in group_A:\n",
    "        if i != j:\n",
    "            B_on[i, j] = 0.3*(1+randscale*np.random.randn())\n",
    "for i in group_B:\n",
    "    for j in group_B:\n",
    "        if i != j:\n",
    "            B_on[i, j] = 0.25*(1+randscale*np.random.randn())\n",
    "\n",
    "# Between-team inhibition\n",
    "for i in group_A:\n",
    "    for j in group_B:\n",
    "        B_off[i, j] = 0.25*(1+randscale*np.random.randn())\n",
    "        B_off[j, i] = 0.25*(1+randscale*np.random.randn())\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Sparsify B_on and B_off\n",
    "# ---------------------------\n",
    "sparsity_level = 0.70  # Set between 0 (dense) and 1 (very sparse)\n",
    "rng = np.random.default_rng(seed=42)  # For reproducibility\n",
    "\n",
    "# Randomly set a proportion of non-diagonal entries to zero\n",
    "def sparsify_matrix(B, sparsity):\n",
    "    mask = rng.random(B.shape) > sparsity\n",
    "    np.fill_diagonal(mask, True)  # Keep diagonals if needed (optional)\n",
    "    return B * mask\n",
    "\n",
    "B_on = sparsify_matrix(B_on, sparsity_level)\n",
    "B_off = sparsify_matrix(B_off, sparsity_level)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Numba-accelerated functions\n",
    "# ---------------------------\n",
    "@njit\n",
    "def hill_rate(x, K, n, k_max=1.0):\n",
    "    return k_max * x**n / (K**n + x**n + 1e-8)\n",
    "\n",
    "@njit\n",
    "def simulate_expression(T, dt, beta, gamma, K, n, noise_strength, B_on, B_off, T_burnin):\n",
    "    N = len(beta)\n",
    "    T_total = T + T_burnin  # total steps = burn-in + recording\n",
    "    x = np.zeros((T, N))    # only record after burn-in\n",
    "    s = np.random.randint(0, 2, N)\n",
    "    remaining_time = np.random.exponential(1.0, size=N)\n",
    "    sqrt_dt = np.sqrt(dt)\n",
    "\n",
    "    x_state = np.zeros(N)  # current expression state\n",
    "\n",
    "    for t in range(T_total):\n",
    "        input_on = B_on @ x_state\n",
    "        input_off = B_off @ x_state\n",
    "\n",
    "        k_on = hill_rate(input_on, K, n)\n",
    "        k_off = hill_rate(input_off, K, n)\n",
    "\n",
    "        for i in range(N):\n",
    "            k_on[i] = min(max(k_on[i], 1e-3), 10.0)\n",
    "            k_off[i] = min(max(k_off[i], 1e-3), 10.0)\n",
    "\n",
    "        remaining_time -= dt\n",
    "        for i in range(N):\n",
    "            if remaining_time[i] <= 0:\n",
    "                if s[i] == 0:\n",
    "                    s[i] = 1\n",
    "                    remaining_time[i] = np.random.exponential(1.0 / k_off[i])\n",
    "                else:\n",
    "                    s[i] = 0\n",
    "                    remaining_time[i] = np.random.exponential(1.0 / k_on[i])\n",
    "\n",
    "        dx = beta * s - gamma * x_state\n",
    "        noise = np.random.normal(0, noise_strength, N) * sqrt_dt\n",
    "        x_state = np.maximum(0.0, x_state + dt * dx + noise)\n",
    "\n",
    "        if t >= T_burnin:\n",
    "            x[t - T_burnin] = x_state\n",
    "\n",
    "    return x\n",
    "T_burnin = 0  # e.g. discard first 200,000 steps\n",
    "# T = 10**6\n",
    "x_control = simulate_expression(T, dt=dt, beta=beta, gamma=gamma,\n",
    "                                K=K, n=n, noise_strength=noise_strength,\n",
    "                                B_on=B_on, B_off=B_off,\n",
    "                                T_burnin=T_burnin)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming x is your simulation output of shape (T, N_genes)\n",
    "# Define team indices\n",
    "group_A = np.arange(0, N_genes // 2)\n",
    "group_B = np.arange(N_genes // 2, N_genes)\n",
    "\n",
    "# Compute average expression over time for each team\n",
    "avg_A = np.mean(x_control[:, group_A], axis=1)\n",
    "avg_B = np.mean(x_control[:, group_B], axis=1)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(avg_A, label='Team A (Genes 0–9)', color='blue', alpha = .4)\n",
    "plt.plot(avg_B, label='Team B (Genes 10–19)', color='red', alpha = .4)\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Average Gene Expression\")\n",
    "# plt.title(\"Average Expression Over Time: Team A vs Team B\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt_out = os.path.join(out_dir, 'teams_net_traj.svg')\n",
    "plt.savefig(plt_out, format='svg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Style\n",
    "sns.set(style=\"whitegrid\", context=\"talk\", palette=\"deep\")\n",
    "\n",
    "# ---- Step 1: Calculate Control Mean and Covariance\n",
    "mu_control = np.mean(x_control, axis=0)\n",
    "Sigma = np.cov(x_control.T)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(Sigma, annot=False, cmap='coolwarm', square=True,\n",
    "            cbar_kws={\"label\": \"Covariance\"}, xticklabels=1, yticklabels=1)\n",
    "\n",
    "plt.title(\"Covariance Matrix Σ of Control Expression\")\n",
    "plt.xlabel(\"Gene Index\")\n",
    "plt.ylabel(\"Gene Index\")\n",
    "plt.tight_layout()\n",
    "plt_out = os.path.join(out_dir, 'teams_net_corr.svg')\n",
    "plt.savefig(plt_out, format='svg')\n",
    "plt.show()\n",
    "\n",
    "# ---- Step 2: Knockdown Gene 0 by a range of fractions\n",
    "fractions = np.linspace(0.1, 1., 10)\n",
    "fractions = [1.]\n",
    "gene_idx = 0\n",
    "X_deltas = []\n",
    "X_preds = []\n",
    "\n",
    "for frac in fractions:\n",
    "    beta_pert = beta.copy()\n",
    "    beta_pert[gene_idx] = beta[gene_idx] * (1 - frac)\n",
    "    x_perturbed = simulate_expression(T, dt=dt, beta=beta_pert, gamma=gamma,\n",
    "                                K=K, n=n, noise_strength=noise_strength,\n",
    "                                B_on=B_on, B_off=B_off,\n",
    "                                T_burnin=T_burnin)\n",
    "    mu_pert = np.mean(x_perturbed, axis=0)\n",
    "\n",
    "    delta_X = mu_pert - mu_control\n",
    "    # u = np.zeros(N_genes)\n",
    "    # Solve for optimal u at gene_index\n",
    "    sigma_column = Sigma[:, gene_idx]\n",
    "    u = np.dot(sigma_column, delta_X) / np.dot(sigma_column, sigma_column)\n",
    "    # u[gene_idx] = -beta[gene_idx] * frac\n",
    "\n",
    "    pred = u * sigma_column\n",
    "\n",
    "    X_deltas.append(delta_X)\n",
    "    X_preds.append(pred)\n",
    "\n",
    "X_deltas = np.array(X_deltas)\n",
    "X_preds = np.array(X_preds)\n",
    "\n",
    "\n",
    "\n",
    "for i, frac in enumerate(fractions):\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    sns.scatterplot(x=X_preds[i], y=X_deltas[i], s=80, ax=ax)\n",
    "\n",
    "    min_val = min(X_preds[i].min(), X_deltas[i].min())\n",
    "    max_val = max(X_preds[i].max(), X_deltas[i].max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'k--', label='Ideal: y = x')\n",
    "\n",
    "    r2 = r2_score(X_deltas[i], X_preds[i])\n",
    "    cos_sim = np.dot(X_deltas[i], X_preds[i]) / (np.linalg.norm(X_deltas[i]) * np.linalg.norm(X_preds[i]))\n",
    "    ax.set_title(f\"{int(frac*100)}% Knockdown — R²: {r2:.2f}, Cos: {cos_sim:.2f}\")\n",
    "    ax.set_xlabel(\"Predicted Δx (Σu)\")\n",
    "    ax.set_ylabel(\"Empirical Δx\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt_out = os.path.join(out_dir, 'teams_net_R2.svg')\n",
    "    plt.savefig(plt_out, format='svg')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853b8206-5bca-4ab8-a077-4ad13ee282ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bef210-e219-4cb9-8125-9e24f889c568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c9e0b2-37bf-41fc-8090-3772cd0dfccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa1eb64-a457-4af2-9031-41da8891b808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee70a22-64f6-44b9-9812-0dca89cd9fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cipher",
   "language": "python",
   "name": "cipher"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
